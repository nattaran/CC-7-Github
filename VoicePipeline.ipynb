{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "runtime_attributes": {
        "runtime_version": "2025.07"
      },
      "authorship_tag": "ABX9TyO/dWZHzrkYBB/TkKyIp44l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nattaran/CC-7-Github/blob/master/VoicePipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8Rx35TvT1uu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Mount Google Drive**"
      ],
      "metadata": {
        "id": "SCqyFkqgbMzP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fk0od9nwapa6",
        "outputId": "fc9edda7-54e3-4a3f-db5a-27d7f77f6fdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "fZGunFw-bvKE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Set Working Directory**"
      ],
      "metadata": {
        "id": "3Uj2QQHdbvM7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Update this path to match your Google Drive folder\n",
        "BASE_DIR = '/content/drive/MyDrive/health-tequity-case'\n",
        "os.chdir(BASE_DIR)\n",
        "\n",
        "# Verify\n",
        "print(f\"‚úÖ Current directory: {os.getcwd()}\")\n",
        "print(f\"üìÅ Files in directory: {os.listdir('.')}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nN9RP39Ra-3Q",
        "outputId": "b0009eb2-34db-4aa0-f742-679246b9953b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Current directory: /content/drive/MyDrive/health-tequity-case\n",
            "üìÅ Files in directory: ['Input_Audio_Files', 'Output_Audio_Files', 'Data', 'whisper_transcriptions_with_errors.csv', 'transcriptions_only.csv', 'error_rates_summary.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**install Required Packages**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "HBC5oZPzcJ0j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install packages\n",
        "!pip install -q openai-whisper\n",
        "!pip install -q git+https://github.com/openai/whisper.git\n",
        "!pip install -q librosa soundfile\n",
        "!pip install -q deep-translator\n",
        "!pip install -q gtts\n",
        "!pip install -q jiwer\n",
        "\n",
        "print(\"‚úÖ All packages installed successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_KHF0LbXdm7",
        "outputId": "3b4fb540-432d-41ec-952b-bc10d8edfe6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "‚úÖ All packages installed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import Libraries **"
      ],
      "metadata": {
        "id": "IGlBpc6sdTuD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from datetime import datetime, timedelta\n",
        "from deep_translator import GoogleTranslator\n",
        "from gtts import gTTS\n",
        "import jiwer\n",
        "from jiwer import wer, cer\n",
        "from jiwer import process_words\n",
        "import warnings\n",
        "import torch\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "print(\"‚úÖ All libraries imported successfully!\")\n",
        "\n",
        "# Update this path to match your Google Drive folder\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtBhcDy4UAQW",
        "outputId": "b642d05a-ab15-4a4e-c211-575e58eedb6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ All libraries imported successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Accessing to the Spanish Audio Files **"
      ],
      "metadata": {
        "id": "E59WOIEdNK2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AUDIO_FOLDER = '/content/drive/MyDrive/health-tequity-case/Input_Audio_Files/'  # UPDATE THIS\n",
        "\n",
        "# List all WAV files in the folder\n",
        "audio_files = sorted([f for f in os.listdir(AUDIO_FOLDER) if f.endswith('.wav')])\n",
        "\n",
        "print(f\"üìÅ Found {len(audio_files)} WAV file(s):\")\n",
        "for filename in audio_files:\n",
        "    print(f\"  - {filename}\")"
      ],
      "metadata": {
        "id": "Z3LxD_k5ZAEf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff50ff48-f516-48c1-f54b-b29d95367fcd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÅ Found 4 WAV file(s):\n",
            "  - q1_es.wav\n",
            "  - q2_es.wav\n",
            "  - q3_es.wav\n",
            "  - q4_es.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "GROUND_TRUTH_SPANISH = {\n",
        "    'q1_es.wav': '¬øCu√°les son mis presiones sist√≥lica y diast√≥lica hoy?',\n",
        "    'q2_es.wav': '¬øCu√°les fueron los valores durante la √∫ltima semana?',\n",
        "    'q3_es.wav': '¬øCu√°l es la tendencia de los valores?',\n",
        "    'q4_es.wav': '¬øCu√°les son los rangos normales para una persona como yo?'\n",
        "}\n",
        "\n",
        "# Ground truth English translations\n",
        "# UPDATE THESE with your actual ground truth translations\n",
        "GROUND_TRUTH_ENGLISH = {\n",
        "    'question1.wav': 'What are my systolic and diastolic blood pressures today?',\n",
        "    'question2.wav': 'What were the values over the last week?',\n",
        "    'question3.wav': 'What is the trend of the values?',\n",
        "    'question4.wav': 'What are the normal ranges for a person like me?'\n",
        "}\n",
        "\n",
        "print(\"\\n‚úÖ Ground truth loaded for error rate calculations\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uslBv4vHOcrS",
        "outputId": "e8c5e23a-3794-4aca-fc5e-a2cc8ee9e5a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Ground truth loaded for error rate calculations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3n1Q03i8OqCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Load Whisper Model\n",
        "def load_whisper_model(model_size=\"medium\"):\n",
        "    \"\"\"\n",
        "    Load Whisper model for ASR\n",
        "\n",
        "    Args:\n",
        "        model_size: 'tiny', 'base', 'small', 'medium', 'large'\n",
        "                   'medium' recommended for Spanish (good accuracy/speed balance)\n",
        "\n",
        "    Returns:\n",
        "        Loaded Whisper model\n",
        "    \"\"\"\n",
        "    print(f\"ü§ñ Loading Whisper '{model_size}' model...\")\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    print(f\"   Device: {device}\")\n",
        "\n",
        "    model = whisper.load_model(model_size, device=device)\n",
        "    print(\"‚úÖ Model loaded successfully!\")\n",
        "    return model\n",
        "\n",
        "# Load the model\n",
        "model = load_whisper_model(model_size=\"medium\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6knv0Q-jOpPD",
        "outputId": "329c908c-0faf-45ee-c34d-0bd95e09053e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ü§ñ Loading Whisper 'medium' model...\n",
            "   Device: cpu\n",
            "‚úÖ Model loaded successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Transcription Spanish Audio **"
      ],
      "metadata": {
        "id": "sTv3xZxcPCN5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transcribe_spanish_audio(model, audio_path, task=\"transcribe\"):\n",
        "    \"\"\"\n",
        "    Transcribe Spanish audio file using Whisper\n",
        "\n",
        "    Args:\n",
        "        model: Loaded Whisper model\n",
        "        audio_path: Path to WAV file\n",
        "        task: 'transcribe' (Spanish->Spanish) or 'translate' (Spanish->English)\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with transcription results\n",
        "    \"\"\"\n",
        "    print(f\"üéµ Processing: {audio_path}\")\n",
        "\n",
        "    result = model.transcribe(\n",
        "        audio_path,\n",
        "        language=\"spanish\",  # Specify Spanish for better accuracy\n",
        "        task=task,\n",
        "        verbose=False\n",
        "    )\n",
        "\n",
        "    return result\n"
      ],
      "metadata": {
        "id": "z7NEvp3rO8hI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Process All Audio Files**"
      ],
      "metadata": {
        "id": "fCQ0r227PnhI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_audio_files(model, audio_folder, audio_files):\n",
        "    \"\"\"\n",
        "    Process multiple Spanish audio files from Google Drive\n",
        "\n",
        "    Args:\n",
        "        model: Loaded Whisper model\n",
        "        audio_folder: Path to folder containing audio files\n",
        "        audio_files: List of audio filenames\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with transcription results\n",
        "    \"\"\"\n",
        "    results = []\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"üéØ TRANSCRIBING SPANISH AUDIO FILES\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    for i, audio_file in enumerate(audio_files, 1):\n",
        "        audio_path = os.path.join(audio_folder, audio_file)\n",
        "        print(f\"\\n[{i}/{len(audio_files)}] {audio_file}\")\n",
        "\n",
        "        if not os.path.exists(audio_path):\n",
        "            print(f\"‚ö†Ô∏è  Warning: {audio_path} not found, skipping...\")\n",
        "            continue\n",
        "\n",
        "        # Get Spanish transcription\n",
        "        spanish_result = transcribe_spanish_audio(model, audio_path, task=\"transcribe\")\n",
        "\n",
        "        # Get English translation\n",
        "        english_result = transcribe_spanish_audio(model, audio_path, task=\"translate\")\n",
        "\n",
        "        results.append({\n",
        "            'question_number': i,\n",
        "            'audio_file': audio_file,\n",
        "            'spanish_transcription': spanish_result['text'].strip(),\n",
        "            'english_translation': english_result['text'].strip(),\n",
        "            'language_detected': spanish_result['language']\n",
        "        })\n",
        "\n",
        "        print(f\"   üá™üá∏ Spanish: {spanish_result['text'].strip()}\")\n",
        "        print(f\"   üá¨üáß English: {english_result['text'].strip()}\")\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "# Process all files from Google Drive\n",
        "results_df = process_audio_files(model, AUDIO_FOLDER, audio_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqJbWBB_PbvM",
        "outputId": "c5ac35e7-7606-423c-e067-a697c19f3aee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "üéØ TRANSCRIBING SPANISH AUDIO FILES\n",
            "============================================================\n",
            "\n",
            "[1/4] q1_es.wav\n",
            "üéµ Processing: /content/drive/MyDrive/health-tequity-case/Input_Audio_Files/q1_es.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 324/324 [00:29<00:00, 11.15frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéµ Processing: /content/drive/MyDrive/health-tequity-case/Input_Audio_Files/q1_es.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 324/324 [00:27<00:00, 11.99frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   üá™üá∏ Spanish: ¬øCu√°les son mis valores de presi√≥n arterial hoy?\n",
            "   üá¨üáß English: What are my blood pressure values today?\n",
            "\n",
            "[2/4] q2_es.wav\n",
            "üéµ Processing: /content/drive/MyDrive/health-tequity-case/Input_Audio_Files/q2_es.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 312/312 [00:28<00:00, 11.08frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéµ Processing: /content/drive/MyDrive/health-tequity-case/Input_Audio_Files/q2_es.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 312/312 [00:29<00:00, 10.65frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   üá™üá∏ Spanish: ¬øCu√°les fueron los valores de la √∫ltima semana?\n",
            "   üá¨üáß English: What were the values ‚Äã‚Äãof the last week?\n",
            "\n",
            "[3/4] q3_es.wav\n",
            "üéµ Processing: /content/drive/MyDrive/health-tequity-case/Input_Audio_Files/q3_es.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 261/261 [00:30<00:00,  8.47frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéµ Processing: /content/drive/MyDrive/health-tequity-case/Input_Audio_Files/q3_es.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 261/261 [00:28<00:00,  9.05frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   üá™üá∏ Spanish: ¬øCu√°l es la tendencia de mis valores?\n",
            "   üá¨üáß English: What is the trend of my values?\n",
            "\n",
            "[4/4] q4_es.wav\n",
            "üéµ Processing: /content/drive/MyDrive/health-tequity-case/Input_Audio_Files/q4_es.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 398/398 [00:29<00:00, 13.44frames/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üéµ Processing: /content/drive/MyDrive/health-tequity-case/Input_Audio_Files/q4_es.wav\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 398/398 [00:28<00:00, 14.21frames/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   üá™üá∏ Spanish: ¬øCu√°les son los rangos normales para una persona como yo?\n",
            "   üá¨üáß English: What are the normal ranges for a person like me?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Error Rate Calculation Functions**"
      ],
      "metadata": {
        "id": "1cf4DnjtTxrf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_wer(reference, hypothesis):\n",
        "    \"\"\"\n",
        "    Calculate Word Error Rate (WER)\n",
        "    WER = (Substitutions + Deletions + Insertions) / Total Words in Reference\n",
        "\n",
        "    Args:\n",
        "        reference: Ground truth text\n",
        "        hypothesis: Predicted/transcribed text\n",
        "\n",
        "    Returns:\n",
        "        WER score (0-1), detailed metrics\n",
        "    \"\"\"\n",
        "    # Normalize text (lowercase, strip)\n",
        "    ref = reference.lower().strip()\n",
        "    hyp = hypothesis.lower().strip()\n",
        "\n",
        "    # Calculate WER\n",
        "    wer_score = wer(ref, hyp)\n",
        "\n",
        "    # Get detailed measures\n",
        "    output= process_words(ref, hyp)\n",
        "\n",
        "    return {\n",
        "        'wer': wer_score,\n",
        "        'substitutions': output.substitutions,\n",
        "        'deletions': output.deletions,\n",
        "        'insertions': output.insertions,\n",
        "        'hits': output.hits\n",
        "    }\n",
        "\n",
        "def calculate_cer(reference, hypothesis):\n",
        "    \"\"\"\n",
        "    Calculate Character Error Rate (CER)\n",
        "    CER = (Character Substitutions + Deletions + Insertions) / Total Characters\n",
        "\n",
        "    Args:\n",
        "        reference: Ground truth text\n",
        "        hypothesis: Predicted/transcribed text\n",
        "\n",
        "    Returns:\n",
        "        CER score (0-1)\n",
        "    \"\"\"\n",
        "    ref = reference.lower().strip()\n",
        "    hyp = hypothesis.lower().strip()\n",
        "\n",
        "    cer_score = cer(ref, hyp)\n",
        "    return cer_score\n",
        "\n",
        "def calculate_ser(reference, hypothesis):\n",
        "    \"\"\"\n",
        "    Calculate Sentence Error Rate (SER)\n",
        "    SER = 1 if sentences don't match exactly, 0 if they match\n",
        "\n",
        "    Args:\n",
        "        reference: Ground truth text\n",
        "        hypothesis: Predicted/transcribed text\n",
        "\n",
        "    Returns:\n",
        "        SER score (0 or 1)\n",
        "    \"\"\"\n",
        "    # Normalize for comparison\n",
        "    ref = reference.lower().strip()\n",
        "    hyp = hypothesis.lower().strip()\n",
        "\n",
        "    # SER is 0 if exact match, 1 if not\n",
        "    ser_score = 0 if ref == hyp else 1\n",
        "    return ser_score\n",
        "\n",
        "def calculate_all_error_rates(results_df, ground_truth_spanish):\n",
        "    \"\"\"\n",
        "    Calculate all error rates for Spanish and English transcriptions\n",
        "\n",
        "    Args:\n",
        "        results_df: DataFrame with transcription results\n",
        "        ground_truth_spanish: Dictionary of ground truth Spanish text\n",
        "        ground_truth_english: Dictionary of ground truth English text\n",
        "\n",
        "    Returns:\n",
        "        DataFrame with error rates\n",
        "    \"\"\"\n",
        "    error_rates = []\n",
        "\n",
        "    for idx, row in results_df.iterrows():\n",
        "        audio_file = row['audio_file']\n",
        "\n",
        "        # Spanish error rates (ASR accuracy)\n",
        "        if audio_file in ground_truth_spanish:\n",
        "            spanish_gt = ground_truth_spanish[audio_file]\n",
        "            spanish_hyp = row['spanish_transcription']\n",
        "\n",
        "            spanish_wer_details = calculate_wer(spanish_gt, spanish_hyp)\n",
        "            spanish_cer_score = calculate_cer(spanish_gt, spanish_hyp)\n",
        "            spanish_ser_score = calculate_ser(spanish_gt, spanish_hyp)\n",
        "        else:\n",
        "            spanish_wer_details = {'wer': None, 'substitutions': None, 'deletions': None, 'insertions': None, 'hits': None}\n",
        "            spanish_cer_score = None\n",
        "            spanish_ser_score = None\n",
        "\n",
        "        # English error rates (Translation accuracy)\n",
        "        # if audio_file in ground_truth_english:\n",
        "        #     english_gt = ground_truth_english[audio_file]\n",
        "        #     english_hyp = row['english_translation']\n",
        "\n",
        "        #     english_wer_details = calculate_wer(english_gt, english_hyp)\n",
        "        #     english_cer_score = calculate_cer(english_gt, english_hyp)\n",
        "        #     english_ser_score = calculate_ser(english_gt, english_hyp)\n",
        "        # else:\n",
        "        #     english_wer_details = {'wer': None, 'substitutions': None, 'deletions': None, 'insertions': None, 'hits': None}\n",
        "        #     english_cer_score = None\n",
        "        #     english_ser_score = None\n",
        "\n",
        "        error_rates.append({\n",
        "            'question_number': row['question_number'],\n",
        "            'audio_file': audio_file,\n",
        "\n",
        "            # Spanish metrics\n",
        "            'spanish_wer': spanish_wer_details['wer'],\n",
        "            'spanish_substitutions': spanish_wer_details['substitutions'],\n",
        "            'spanish_deletions': spanish_wer_details['deletions'],\n",
        "            'spanish_insertions': spanish_wer_details['insertions'],\n",
        "            'spanish_cer': spanish_cer_score,\n",
        "            'spanish_ser': spanish_ser_score,\n",
        "\n",
        "            # English metrics\n",
        "            # 'english_wer': english_wer_details['wer'],\n",
        "            # 'english_substitutions': english_wer_details['substitutions'],\n",
        "            # 'english_deletions': english_wer_details['deletions'],\n",
        "            # 'english_insertions': english_wer_details['insertions'],\n",
        "            # 'english_cer': english_cer_score,\n",
        "            # 'english_ser': english_ser_score\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(error_rates)\n",
        "\n",
        "# Calculate error rates\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üìä CALCULATING ERROR RATES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "error_rates_df = calculate_all_error_rates(results_df, GROUND_TRUTH_SPANISH)\n",
        "\n",
        "# Merge with original results\n",
        "full_results_df = results_df.merge(error_rates_df, on=['question_number', 'audio_file'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pS7Y16uDP1I5",
        "outputId": "cb14bbb4-83e5-4613-cc96-c2392e9f612d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "üìä CALCULATING ERROR RATES\n",
            "============================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display Results with Error Rates"
      ],
      "metadata": {
        "id": "qNO4IxAfWS-i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# CELL 7: Display Results with Error Rates\n",
        "# ============================================\n",
        "display_cols = ['question_number', 'audio_file', 'spanish_wer', 'spanish_cer',\n",
        "                'spanish_ser']  #, 'english_wer', 'english_cer', 'english_ser']\n",
        "print(full_results_df[display_cols].to_string(index=False))\n",
        "\n",
        "# Calculate averages (skip None values)\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üìà AVERAGE ERROR RATES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Spanish metrics\n",
        "spanish_wer_mean = full_results_df['spanish_wer'].dropna().mean()\n",
        "spanish_cer_mean = full_results_df['spanish_cer'].dropna().mean()\n",
        "spanish_ser_mean = full_results_df['spanish_ser'].dropna().mean()\n",
        "\n",
        "print(f\"Spanish ASR:\")\n",
        "if not pd.isna(spanish_wer_mean):\n",
        "    print(f\"  Average WER: {spanish_wer_mean:.4f} ({spanish_wer_mean*100:.2f}%)\")\n",
        "    print(f\"  Average CER: {spanish_cer_mean:.4f} ({spanish_cer_mean*100:.2f}%)\")\n",
        "    print(f\"  Average SER: {spanish_ser_mean:.4f} ({spanish_ser_mean*100:.2f}%)\")\n",
        "else:\n",
        "    print(f\"  ‚ö†Ô∏è  No ground truth available for Spanish ASR\")\n",
        "\n",
        "# English metrics\n",
        "# english_wer_mean = full_results_df['english_wer'].dropna().mean()\n",
        "# english_cer_mean = full_results_df['english_cer'].dropna().mean()\n",
        "# english_ser_mean = full_results_df['english_ser'].dropna().mean()\n",
        "\n",
        "# print(f\"\\nEnglish Translation:\")\n",
        "# if not pd.isna(english_wer_mean):\n",
        "#     print(f\"  Average WER: {english_wer_mean:.4f} ({english_wer_mean*100:.2f}%)\")\n",
        "#     print(f\"  Average CER: {english_cer_mean:.4f} ({english_cer_mean*100:.2f}%)\")\n",
        "#     print(f\"  Average SER: {english_ser_mean:.4f} ({english_ser_mean*100:.2f}%)\")\n",
        "# else:\n",
        "#     print(f\"  ‚ö†Ô∏è  No ground truth available for English translation\")\n",
        "\n",
        "# ============================================\n",
        "# SAVE RESULTS\n",
        "# ============================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üíæ SAVING RESULTS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Save full results with all columns\n",
        "output_file_full = \"whisper_transcriptions_with_errors.csv\"\n",
        "full_results_df.to_csv(output_file_full, index=False)\n",
        "print(f\"‚úÖ Full results saved to: {output_file_full}\")\n",
        "\n",
        "# Save transcriptions only (simplified)\n",
        "transcriptions_only = full_results_df[['question_number', 'audio_file',\n",
        "                                        'spanish_transcription', 'english_translation']].copy()\n",
        "output_file_transcriptions = \"transcriptions_only.csv\"\n",
        "transcriptions_only.to_csv(output_file_transcriptions, index=False)\n",
        "print(f\"‚úÖ Transcriptions only saved to: {output_file_transcriptions}\")\n",
        "\n",
        "# Save error rates summary\n",
        "error_summary = full_results_df[['question_number', 'audio_file',\n",
        "                                  'spanish_wer', 'spanish_cer', 'spanish_ser']].copy()\n",
        "output_file_errors = \"error_rates_summary.csv\"\n",
        "error_summary.to_csv(output_file_errors, index=False)\n",
        "print(f\"‚úÖ Error rates summary saved to: {output_file_errors}\")\n",
        "\n",
        "# Save to Google Drive (if mounted)\n",
        "try:\n",
        "    # Try to save to Drive if it's mounted\n",
        "    drive_output_folder = '/content/drive/MyDrive/health_tequity_results/'\n",
        "    os.makedirs(drive_output_folder, exist_ok=True)\n",
        "\n",
        "    full_results_df.to_csv(os.path.join(drive_output_folder, output_file_full), index=False)\n",
        "    transcriptions_only.to_csv(os.path.join(drive_output_folder, output_file_transcriptions), index=False)\n",
        "    error_summary.to_csv(os.path.join(drive_output_folder, output_file_errors), index=False)\n",
        "\n",
        "    print(f\"\\n‚úÖ All files also saved to Google Drive: {drive_output_folder}\")\n",
        "except:\n",
        "    print(\"\\n‚ö†Ô∏è  Google Drive not mounted - files saved locally only\")\n",
        "\n",
        "# Download files to your computer\n",
        "print(\"\\nüì• Download files to your computer:\")\n",
        "from google.colab import files\n",
        "files.download(output_file_full)\n",
        "files.download(output_file_transcriptions)\n",
        "files.download(output_file_errors)\n",
        "\n",
        "print(\"\\n‚úÖ All results saved successfully!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "id": "DBUCBm1nUOdu",
        "outputId": "bfe39888-fcdc-4352-d211-ff6f9236e757"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " question_number audio_file  spanish_wer  spanish_cer  spanish_ser\n",
            "               1  q1_es.wav     0.500000     0.452830            1\n",
            "               2  q2_es.wav     0.125000     0.096154            1\n",
            "               3  q3_es.wav     0.142857     0.054054            1\n",
            "               4  q4_es.wav     0.000000     0.000000            0\n",
            "\n",
            "============================================================\n",
            "üìà AVERAGE ERROR RATES\n",
            "============================================================\n",
            "Spanish ASR:\n",
            "  Average WER: 0.1920 (19.20%)\n",
            "  Average CER: 0.1508 (15.08%)\n",
            "  Average SER: 0.7500 (75.00%)\n",
            "\n",
            "============================================================\n",
            "üíæ SAVING RESULTS\n",
            "============================================================\n",
            "‚úÖ Full results saved to: whisper_transcriptions_with_errors.csv\n",
            "‚úÖ Transcriptions only saved to: transcriptions_only.csv\n",
            "‚úÖ Error rates summary saved to: error_rates_summary.csv\n",
            "\n",
            "‚úÖ All files also saved to Google Drive: /content/drive/MyDrive/health_tequity_results/\n",
            "\n",
            "üì• Download files to your computer:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_33d17cc8-f5e7-488a-a298-8dd829e6e4b2\", \"whisper_transcriptions_with_errors.csv\", 761)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_79a504c9-f414-455f-9891-e09a9642ebde\", \"transcriptions_only.csv\", 487)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_85281ef6-0a94-4c10-a002-62eb3e0b1b2e\", \"error_rates_summary.csv\", 216)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ All results saved successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save Results"
      ],
      "metadata": {
        "id": "_99qcHNtWs6W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display Individual Results with Comparision"
      ],
      "metadata": {
        "id": "NSgaaG_9XEGf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üìù DETAILED TRANSCRIPTIONS WITH GROUND TRUTH COMPARISON\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for idx, row in full_results_df.iterrows():\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Question {row['question_number']}: {row['audio_file']}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    # Spanish comparison\n",
        "    print(f\"\\nüá™üá∏ SPANISH:\")\n",
        "    audio_file = row['audio_file']\n",
        "    if audio_file in GROUND_TRUTH_SPANISH:\n",
        "        print(f\"  Ground Truth: {GROUND_TRUTH_SPANISH[audio_file]}\")\n",
        "        print(f\"  Transcribed:  {row['spanish_transcription']}\")\n",
        "\n",
        "        # Display metrics if available\n",
        "        if row['spanish_wer'] is not None:\n",
        "            print(f\"  WER: {row['spanish_wer']:.4f} | CER: {row['spanish_cer']:.4f} | SER: {row['spanish_ser']}\")\n",
        "            print(f\"  Errors: Subs={row['spanish_substitutions']}, Dels={row['spanish_deletions']}, Ins={row['spanish_insertions']}\")\n",
        "        else:\n",
        "            print(f\"  ‚ö†Ô∏è  No ground truth available for error calculation\")\n",
        "    else:\n",
        "        print(f\"  Transcribed:  {row['spanish_transcription']}\")\n",
        "        print(f\"  ‚ö†Ô∏è  No ground truth available\")\n",
        "\n",
        "    # # English comparison\n",
        "    # print(f\"\\nüá¨üáß ENGLISH:\")\n",
        "    # if audio_file in GROUND_TRUTH_ENGLISH:\n",
        "    #     print(f\"  Ground Truth: {GROUND_TRUTH_ENGLISH[audio_file]}\")\n",
        "    #     print(f\"  Translated:   {row['english_translation']}\")\n",
        "\n",
        "    #     # Display metrics if available\n",
        "    #     if row['english_wer'] is not None:\n",
        "    #         print(f\"  WER: {row['english_wer']:.4f} | CER: {row['english_cer']:.4f} | SER: {row['english_ser']}\")\n",
        "    #         print(f\"  Errors: Subs={row['english_substitutions']}, Dels={row['english_deletions']}, Ins={row['english_insertions']}\")\n",
        "    #     else:\n",
        "    #         print(f\"  ‚ö†Ô∏è  No ground truth available for error calculation\")\n",
        "    # else:\n",
        "    #     print(f\"  Translated:   {row['english_translation']}\")\n",
        "    #     print(f\"  ‚ö†Ô∏è  No ground truth available\")\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YgSuvBnOXLR6",
        "outputId": "9b1f04c3-310c-4635-d9f3-788688f743fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "üìù DETAILED TRANSCRIPTIONS WITH GROUND TRUTH COMPARISON\n",
            "============================================================\n",
            "\n",
            "============================================================\n",
            "Question 1: q1_es.wav\n",
            "============================================================\n",
            "\n",
            "üá™üá∏ SPANISH:\n",
            "  Ground Truth: ¬øCu√°les son mis presiones sist√≥lica y diast√≥lica hoy?\n",
            "  Transcribed:  ¬øCu√°les son mis valores de presi√≥n arterial hoy?\n",
            "  WER: 0.5000 | CER: 0.4528 | SER: 1\n",
            "  Errors: Subs=4, Dels=0, Ins=0\n",
            "\n",
            "\n",
            "============================================================\n",
            "Question 2: q2_es.wav\n",
            "============================================================\n",
            "\n",
            "üá™üá∏ SPANISH:\n",
            "  Ground Truth: ¬øCu√°les fueron los valores durante la √∫ltima semana?\n",
            "  Transcribed:  ¬øCu√°les fueron los valores de la √∫ltima semana?\n",
            "  WER: 0.1250 | CER: 0.0962 | SER: 1\n",
            "  Errors: Subs=1, Dels=0, Ins=0\n",
            "\n",
            "\n",
            "============================================================\n",
            "Question 3: q3_es.wav\n",
            "============================================================\n",
            "\n",
            "üá™üá∏ SPANISH:\n",
            "  Ground Truth: ¬øCu√°l es la tendencia de los valores?\n",
            "  Transcribed:  ¬øCu√°l es la tendencia de mis valores?\n",
            "  WER: 0.1429 | CER: 0.0541 | SER: 1\n",
            "  Errors: Subs=1, Dels=0, Ins=0\n",
            "\n",
            "\n",
            "============================================================\n",
            "Question 4: q4_es.wav\n",
            "============================================================\n",
            "\n",
            "üá™üá∏ SPANISH:\n",
            "  Ground Truth: ¬øCu√°les son los rangos normales para una persona como yo?\n",
            "  Transcribed:  ¬øCu√°les son los rangos normales para una persona como yo?\n",
            "  WER: 0.0000 | CER: 0.0000 | SER: 0\n",
            "  Errors: Subs=0, Dels=0, Ins=0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LLM **part**"
      ],
      "metadata": {
        "id": "GrhFIv4iLMze"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install transformers accelerate bitsandbytes sentencepiece einops safetensors\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhwghRtXgFPd",
        "outputId": "4f326e1e-50ec-410a-9f8e-feeb6b12467e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m60.1/60.1 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m45.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: see what Colab gave you\n",
        "!nvidia-smi || true\n",
        "\n",
        "import sys, platform\n",
        "print(\"Python:\", sys.version)\n",
        "print(\"Platform:\", platform.platform())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRYP59Bua6ai",
        "outputId": "a7ff76ae-d72b-4d31-8d8e-f5d2baf2ab05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Oct 17 18:25:54 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   34C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "Python: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n",
            "Platform: Linux-6.6.105+-x86_64-with-glibc2.35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install \"openai==1.51.2\" \"httpx==0.27.2\" \"httpcore==1.0.5\" pandas\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6k8tLuCbBUX",
        "outputId": "fb572cc9-ad55-481a-f450-87d46eebd354"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/383.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m383.7/383.7 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/76.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/77.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/58.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "firebase-admin 6.9.0 requires httpx[http2]==0.28.1, but you have httpx 0.27.2 which is incompatible.\n",
            "google-genai 1.25.0 requires httpx<1.0.0,>=0.28.1, but you have httpx 0.27.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "api_key = userdata.get(\"OPENAI_API_KEY\")\n",
        "if not api_key:\n",
        "    raise RuntimeError(\"Add OPENAI_API_KEY in the Secrets panel (left sidebar, key icon).\")"
      ],
      "metadata": {
        "id": "Ck_XFBifbLES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the CSV from google drive\n",
        "\n",
        "from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "CSV_PATH = \"/content/drive/MyDrive/health-tequity-case/Data/synthetic_bp_one_person.csv\""
      ],
      "metadata": {
        "id": "BN8OgxmIdIKF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CSV as plain text\n",
        "csv_text = open(CSV_PATH, \"r\", encoding=\"utf-8\").read()\n",
        "print(\"\\n\".join(csv_text.splitlines()[:5]))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XFXdNOPeVDl",
        "outputId": "9475da80-48a8-41c3-c8fb-21c115979119"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "date,age,sex,systolic_mmHg,diastolic_mmHg,regime,category\n",
            "2025-09-17,68,Female,116,77,normal,normal\n",
            "2025-09-18,68,Female,126,70,normal,elevated\n",
            "2025-09-19,68,Female,123,81,normal,elevated\n",
            "2025-09-20,68,Female,117,79,normal,normal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Define Templates + GPT call (JSON output)**"
      ],
      "metadata": {
        "id": "q_Jyz09XejJv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json, re\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(api_key=api_key)\n",
        "\n",
        "TEMPLATES = {\n",
        "    \"today\":         \"Your systolic blood pressure was {sys} mm of Hg and your diastolic blood pressure was {dia} mm of Hg.\",\n",
        "    \"last_week\":     \"Over the last week, your systolic blood pressure has averaged {sys_avg} mm of Hg and your diastolic blood pressure has averaged {dia_avg} mm of Hg.\",\n",
        "    \"trend_month\":   \"The trend for the values over the last month has been {trend} average values of your systolic blood pressure and diastolic blood pressure.\",\n",
        "    \"normal_ranges\": \"While each person‚Äôs normal range should be discussed with their physician, literature suggests that for a {sex} aged {age} years, systolic and diastolic blood pressure can typically be expected to be {sys_norm} mm Hg and {dia_norm} mm Hg respectively. This information was retrieved from {reference}.\"\n",
        "}\n",
        "\n",
        "SYSTEM = \"\"\"You are a careful data analyst.\n",
        "Do ALL analysis yourself using ONLY the CSV provided by the user.\n",
        "Interpret columns: date, age, sex, systolic, diastolic.\n",
        "- \"Today\" = most recent row by date.\n",
        "- \"Last week\" = last 7 rows by date (including the most recent).\n",
        "- \"Trend over the last month\" = last 30 rows; return one of: increasing / decreasing / stable.\n",
        "- If a specific date is mentioned (e.g., 'on October 1'), return that date‚Äôs values if present.\n",
        "Return STRICT JSON ONLY:\n",
        "{\n",
        " \"template\": \"today\"|\"last_week\"|\"trend_month\"|\"normal_ranges\",\n",
        " \"fields\": {...},   # only the slots the chosen template needs (e.g., sys, dia, sys_avg, dia_avg, trend, age, sex, sys_norm, dia_norm, reference, date)\n",
        " \"final_text\": \"one sentence exactly following the chosen template with mm of Hg units\"\n",
        "}\n",
        "No extra prose. JSON only.\n",
        "\"\"\"\n",
        "\n",
        "def ask_gpt(question_en: str, csv_block: str) -> dict:\n",
        "    user = f\"CSV:\\n{csv_block}\\n\\nQUESTION:\\n{question_en}\\n\\nReturn JSON only.\"\n",
        "    resp = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",     # or \"gpt-4o-mini\" for lower cost\n",
        "        temperature=0,\n",
        "        messages=[\n",
        "            {\"role\":\"system\",\"content\":SYSTEM},\n",
        "            {\"role\":\"system\",\"content\":\"Templates:\\n\" + json.dumps(TEMPLATES)},\n",
        "            {\"role\":\"user\",\"content\":user}\n",
        "        ]\n",
        "    ).choices[0].message.content\n",
        "\n",
        "    # Strip possible code fences and parse only the JSON blob\n",
        "    clean = re.sub(r\"^```json|```$\", \"\", resp.strip(), flags=re.M|re.I)\n",
        "    start, end = clean.find(\"{\"), clean.rfind(\"}\")\n",
        "    return json.loads(clean[start:end+1])\n",
        "\n"
      ],
      "metadata": {
        "id": "tIP2Nmy8LQ48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Run the 4 required question and save results**"
      ],
      "metadata": {
        "id": "-DrRxc51e6Vs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd, os\n",
        "\n",
        "questions = [\n",
        "    \"What are my systolic and diastolic blood pressures today?\",\n",
        "    \"What were the values over the last week?\",\n",
        "    \"What is the trend of the values over the last month?\",\n",
        "    \"What are the normal ranges for a person like me?\",\n",
        "    # Optional extension:\n",
        "    \"What were my blood pressure values on October 1?\"\n",
        "]\n",
        "\n",
        "rows = []\n",
        "for q in questions:\n",
        "    obj = ask_gpt(q, csv_text)\n",
        "    rows.append({\n",
        "        \"question\": q,\n",
        "        \"template\": obj.get(\"template\"),\n",
        "        \"fields\": json.dumps(obj.get(\"fields\", {}), ensure_ascii=False),\n",
        "        \"answer_en\": obj.get(\"final_text\")\n",
        "    })\n",
        "    print(f\"\\nQ: {q}\\nA: {obj.get('final_text')}\")\n",
        "\n",
        "os.makedirs(\"/content/data\", exist_ok=True)\n",
        "out_path = \"/content/data/llm_answers_en_colab.csv\"\n",
        "pd.DataFrame(rows).to_csv(out_path, index=False, encoding=\"utf-8-sig\")\n",
        "print(f\"\\n‚úÖ Saved: {out_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A63bKwRve5qA",
        "outputId": "59b7e453-71ad-4d78-e1d8-4bf7323f867e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Q: What are my systolic and diastolic blood pressures today?\n",
            "A: Your systolic blood pressure was 110 mm of Hg and your diastolic blood pressure was 76 mm of Hg.\n",
            "\n",
            "Q: What were the values over the last week?\n",
            "A: Over the last week, your systolic blood pressure has averaged 139 mm of Hg and your diastolic blood pressure has averaged 92 mm of Hg.\n",
            "\n",
            "Q: What is the trend of the values over the last month?\n",
            "A: The trend for the values over the last month has been increasing average values of your systolic blood pressure and diastolic blood pressure.\n",
            "\n",
            "Q: What are the normal ranges for a person like me?\n",
            "A: While each person‚Äôs normal range should be discussed with their physician, literature suggests that for a Female aged 68 years, systolic and diastolic blood pressure can typically be expected to be 120-129 mm Hg and 80-84 mm Hg respectively. This information was retrieved from European Society of Cardiology (ESC) guidelines.\n",
            "\n",
            "Q: What were my blood pressure values on October 1?\n",
            "A: Your systolic blood pressure was 121 mm of Hg and your diastolic blood pressure was 77 mm of Hg.\n",
            "\n",
            "‚úÖ Saved: /content/data/llm_answers_en_colab.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6vuVUaMfMGJ1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}